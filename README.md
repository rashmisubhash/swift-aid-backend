# Swift Aid Backend

An AI-powered, multi-turn emergency response system built on AWS. Swift Aid listens to a caller in real time, transcribes their audio, generates a concise, action-oriented response via Amazon Bedrock, synthesizes it to speech with Amazon Polly, and plays it back—all within a single call flow.

# Features

- Real-time streaming of caller audio from Amazon Connect into Kinesis Data Streams
- Live transcription via Amazon Transcribe Streaming
- AI response using Amazon Bedrock (Claude model) with a safety-first system prompt
- Text-to-speech replies generated by Amazon Polly and stored in S3
- Seamless back-and-forth within one phone call: record → transcribe → think → speak → listen → repeat

# Components

## Contact Flow (Amazon Connect)
Greeting: Text-to-speech prompt.

Start/Stop Media Streaming: Streams raw PCM @ 8 kHz into a Kinesis Data Stream (SwiftAI‐AudioStream), keyed by ContactId.

Wait + Check: Polls Contact Attribute AudioUri until your orchestrator writes a URL.

Play Prompt: Plays the S3 URL via the $['Attributes']['AudioUri'] expression.

Invoke Lambda (ClearAudioUri): Clears the URL so the loop can repeat.

## swiftresponse Lambda
Trigger: Kinesis Data Stream (audio chunks).

Function:

Decode base64 → raw PCM.

Stream to Amazon Transcribe Streaming.

For each non-partial transcript, put_item into DynamoDB (SwiftAI-Conversations) with Speaker="Human".

Dependencies:

amazon-transcribe & awscrt (packaged via a Lambda layer).

IAM: kinesis:GetRecords, transcribe:StartStreamTranscription, dynamodb:PutItem.

## SwiftAIOrchestrator Lambda
Trigger: DynamoDB Stream on SwiftAI-Conversations (new image).

Function:

Filter for Speaker="Human".

Query full conversation history from DynamoDB.

Invoke Bedrock model (anthropic.claude-v2) with a safety-focused system prompt.

Save AI turn back into DynamoDB (Speaker="Assistant").

Synthesize response via Polly (Joanna, neural), upload MP3 to S3 (swiftai-responses/<ContactId>/<ts>.mp3).

Call connect.update_contact_attributes(InstanceId, ContactId, Attributes={"AudioUri": "<full S3 URL>"}).

## Env Vars:

CONNECT_INSTANCE_ID=your_connect_instance_id
CONVERSATION_TABLE=SwiftAI-Conversations
AUDIO_BUCKET=swiftai-responses
AWS_REGION=us-east-1


## ClearAudioUri Lambda

⚙️ Setup & Deployment
Provision AWS resources

Create S3 buckets: swiftai-responses (for MP3s).

Create DynamoDB table: SwiftAI-Conversations (Partition Key: ContactId, Sort Key: Timestamp).

Create Kinesis Data Stream: SwiftAI-AudioStream.

Enable Live Media Streaming in Connect (prefix optional).

Build & deploy Lambdas

swiftresponse:

Package code + amazon-transcribe & awscrt via Lambda layer.

Attach Kinesis trigger.

SwiftAIOrchestrator:

Attach DynamoDB Stream trigger.

ClearAudioUri: standalone.

Configure IAM roles for each Lambda with only needed permissions.

Configure Contact Flow in Amazon Connect:

Drag in blocks per the diagram.

Use $['Attributes']['AudioUri'] in the Play Prompt’s S3 file path (set manually).

Map Error branches to Disconnect only; loop Success as described.

Test end-to-end: call in, speak, watch logs & DynamoDB/S3, hear AI responses.




